%%
%% This is file `sample-sigchi.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigchi')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigchi.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigchi]{acmart}
%\usepackage [slovene]{babel}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{graphicx}
\usepackage[utf8]{inputenc}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\copyrightyear{2018}
%\acmYear{2018}
%\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
%\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
%  Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY}
%\acmPrice{15.00}
%\acmISBN{978-1-4503-9999-9/18/06}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Sound 2121: The Future of Music is Natural}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Jordan Aiko Deja}
\email{jordan.deja@famnit.upr.si}
\affiliation{%
  \institution{University of Primorska\\UP FAMNIT}
  \streetaddress{Glagoljaška 8}
  \city{Koper}
  \state{Slovenia}
  \postcode{SI-6000}
}

\author{Nuwan Attygale}
\email{nuwan.attygalle@upr.si}
\affiliation{%
  \institution{University of Primorska\\UP FAMNIT}
  \streetaddress{Glagoljaška 8}
    \city{Koper}
  \state{Slovenia}
  \postcode{SI-6000}
}

\author{Klen Čopič Pucihar}
\authornotemark[1]
\email{klen.copic@famnit.upr.si}
\affiliation{%
  \institution{University of Primorska\\UP FAMNIT}
  \streetaddress{Glagoljaška 8}
  \city{Koper}
  \state{Slovenia}
  \postcode{SI-6000}
}
\affiliation{%
  \institution{Fakulteta za Informacijske Študije}
  \streetaddress{Glagoljaška 8}
  \city{Novo mesto}
  \state{Slovenija}
  \postcode{SI-6000}
}

\author{Matjaž Kljun}
\email{matjaz.kljun@famnit.upr.si}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{University of Primorska\\UP FAMNIT}
  \streetaddress{Glagoljaška 8}
  \city{Koper}
  \state{Slovenia}
  \postcode{SI-6000}
}
\affiliation{%
  \institution{Fakulteta za Informacijske Študije}
  \streetaddress{Glagoljaška 8}
  \city{Novo mesto}
  \state{Slovenija}
  \postcode{SI-6000}
}

\settopmatter{printacmref=false}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
 Music has always been an integral part of our society since the prehistoric times. For the past five centuries, music instruments have been perfected and the industry is nowadays worth billions of dollars. With recent innovations in computer interfaces, music information retrieval and artificial intelligence, playing music is not in the sole domain of humans anymore. Thus we are faced with the questions: ``What really is music? What is the future of music? How will we consume music a hundred years from now?'' In this paper, we shortly present how music has been consumed throughout history how we imagine it a century from now. We make a wild speculation about the future of music and its interface, while encouraging the discussion regarding these visions. 
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003123.10011758</concept_id>
       <concept_desc>Human-centered computing~Interaction design theory, concepts and paradigms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Interaction design theory, concepts and paradigms}
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{music, interface, interaction design, sound}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
  \includegraphics[width=\textwidth]{acmart-master-2/samples/test2bw.png}
  \caption{Concept: We see a future where we no longer need tangible interfaces. Rather humans would let go of these interfaces to give way to a more natural and seamless music interface.}
  \Description{photo of a user removing headphones.}
  \label{fig:teaser}
\end{teaserfigure}
%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
%Humans have been listening to music since 

Music is considered to be culturally universal \cite{campbell1997music, seeger1971reflections} and present across all parts of the globe, reshaping the ways human live, express themselves and convey emotions  \cite{juslin2001music,montagu2017music}. Humans have been expressing themselves through music for a very long time.  It is believed that music originated from naturally occurring sounds and rhythms that humans echoed by merging them in patterns, making repetitions while changing tonality using their voice, hands clapping \cite{kassler1987dancing}, and smacking stones, sticks and other objects around them \cite{montagu2014horns}. For example, one of such ambient sound is rain, that has a calming and a relaxing effect, even now since early humans felt safe during the rain while predators do not hunt \cite{aramaki2017bridging}. Music has also helped humans 
in terms of survival, forging a sense of group identity and mutual trust \cite{conard2009new}.

The voice box which allowed humans to sing first emerged about a million years \cite{montagu2017music} ago but they only developed how to use it around 530,000 years ago~\cite{morley2013prehistory}. The voice box was considered as the first music instrument. Besides voice and hands, the earlier instruments were the objects found in the environment such as sticks and stones. Some authors argue that since the oldest instruments found are so sophisticated (such as the 42,000 year-old bone flute \cite{higham2012tauesting,wallin2001origins,conard2009new}) there must have been less sophisticated instruments used by humans before \cite{conard2009new,morley2013prehistory}. Nevertheless, the instruments the humans made and used have rapidly evolved together with the complexity of music compositions in the last couple of centuries. In this period a variety of string, brass, percussion and woodwind instruments have evolved from earlier less sophisticated instruments \cite{conard2009female}.

As newer technologies are introduced, other ways of creating, producing, interacting with and even sharing music \cite{voida2005listening} are also taking place. MIDI interfaces, electric guitars and synthesizers are just some of the devices made of circuits that imitate traditional music instruments, and can be connected to the computer. Novel algorithms, music information retrieval (MIR)~\cite{downie2008music,downie2003music} and artificial intelligence (AI) techniques allow us to work with computers in creating new music content. With the advent of social platforms, sharing music on a grand scale has become a norm.

Throughout this evolution one of the main components of music is expressing and generating emotions. Changes in vocal parameters occurring during speech as well as singing have been shown to effect our state of emotions \cite{kappert2019aim}. It has been also confirmed that sadness, happiness and other emotions can be communicated to listeners by music composers. As such, music is considered as a popular and easily-applicable means for triggering emotions \cite{kappert2019aim} and is globally consumed by everyone. We listen to music in order to make us happy, sad and  reflect on our emotions. 

This paper attempts to share the authors' visions on how humans will consume and interact with music in the future. We present our position based on the trends in how music instruments and music consumption have evolved throughout the history. These visions have also emerged from shared ideas in our small crowd-sourcing study we conducted online. We present three distinct scenarios of how future music consumption might look like. Lastly, we present questions and challenges that provoke discussions involving usability, security, intellectual property and many other relevant key topics on music. 

%, (2) how humans have used them and (3) how can we go back to a more natural but technologically-empowered musical experiences. 
 %where our musical interface can be best applied. 

\section{Re-imagining music and the music interface}

% paragraph 1: music an experience that you can be immersed in without losing touch of reality
Humans create and consume music for four different purposes: (1) dancing as a social exercise, (2) providing a common form of personal or community entertainment, (3) communicating our ideas and emotions and (4) having and celebrating rituals and other activities \cite{montagu2017music}. While these purposes come in handy for a variety of music activities, this position paper is focusing on music listening only. This is present in (1) where listening is a shared experience, as well as in (2) and (4) where listening can be a  shared and also a personal experience. 

When looking at how music listening has evolved in history, we can envision human tribes gathered around the fire where one or several members performed a music piece. This type of music listening has been present for a long period where people had to gather in concert halls to be able to listen to music. With recordings, music has moved to people's homes and the group of listeners have been changed to family members and listening has become more personal. The headphones enabled users to experience music individually and the Walkman enabled this to listen music on-the-go. Smartphones and internet have expanded the instant availability of music but the consumption remained personal. The advances in virtually reality (VR) and augmented reality (AR) have made personal music listening an immersive experience with lights and visualisations augmenting music. Looking at how listening to music has moved closer and closer to us with in-ear headphones that we even try to insert as close as possible to our body, it is not far-fetched if our vision is that listening to music will be inside our heads.
% FOCUS ON CONSUMIN ... 
% - creating music
% - gather at the particular time in particular place to listen to it
% - recording music: listening to it at home - group listening
% - walkman: listening to music on the go - personal
% - internet -> sharing -> social -> personal (phones) 
% - even more personal in ourselves intimate ... 
%The visions we present are anchored on these purposes and are aligned with technological innovations involving musical instruments that attempt to address open problems in music. Nowadays, it is common to use AI techniques to help humans compose music [semi-]automatically; use MIR algorithms to help composers express their emotions and use 
 %We envision the future of a music interface that combines all these innovations into a natural interface. We present two ways on how we re-imagined them: 
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{acmart-master-2/samples/thinkbnw.png}
  \caption{Concept: Humans do not need tablets, mobile devices, or digital walls. Ideas and concepts are conceived in and are played into our brains.}
  \Description{Figure of a person thinking and not touching anything.}
  \label{fig: think}
\end{figure}
Music is not just about sounds but is all about rhythmic vibrations; for example, it has been noted that the part of the brain responsible for hearing, works perfectly in deaf people as well \cite{abcsciencemusic}. In order to feel music, we do not need to hear it but rather receive the vibrations to the hearing region of the brain. Because of this, we envision a future where we do not need external devices (such as headphones or speakers) to be able to hear music, enjoy concerts, etc. Rather we will be listening to music within our brain in a seamless way. We envision a future where objects will not have a brutalist or neo-futuristic designs. Rather, we see a future of everyday objects that are connected to the cloud \cite{musk2019integrated} where they have access to superb computing power. These objects will be equipped with special nano-chips that allow them to be part of the global link of information capable of moving themselves depending on the needed use.

This is a vision of IoT \cite{weisman2004internet} and we are expanding it to the music listening. Currently, researchers are experimenting with micro-controllers plugged into the brain and we envision having such devices plugged into our hearing part of our brain. Thereby allowing humans and objects to telepathically-communicate. Sound signals will be delivered straight into our auditory cortex, into the brain directly. People will no longer have to depend on their ears to listen and hear things. As such, people could enjoy music even while spacewalking, diving, skiing or surfing. People will enjoy music and will help them keep going. 

In the future we envision, humans will be able to amplify their emotions by the music naturally produced by the objects surrounding them (see Fig \ref{fig: think}. Algorithms will design and produce rhythms in real-time and have them played via vibration by these nearby objects (moving on their own). Humans will simply need to think of these emotions and sounds, and the objects near them will seamlessly produce the vibrations recreating these sounds. Objects around us, can produce a unique rhythm, providing a new definition of audio augmented reality. Humans will get to enjoy their favorite tunes through this natural interface where instructions and processes are communicated through this neurological link online. We believe that through this neurological interface, humans can create and experience music without losing touch of reality. Humans will be able to perform their daily tasks and be able to seamlessly enjoy the music they hear, produced by the objects around them without having to move a single muscle in their bodies. 

%\textit{Music as a gateway for human emotions}. 
Traditionally, there are two ways on how music becomes a gateway for our emotions. If we feel sad, we wish to hear music so we can reflect, dive deeper and understand the sadness that we feel [emotions going in]. This experience gives us lessons on how to manage our emotions, and how to be stronger. At times, we may feel sad so we wish to hear music in order to improve our mood [emotions going out] and spend the better part of our days. Through our natural and seamless interface, humans can create gateways for their emotions with music. As humans are connected to the global highway of information, unobtrusive sensors no longer need to detect and distinguish the current affect that they feel. Because of their neurological connection to the world, their emotions are easily read and \textit{felt} by the objects around them. Similar to how empathetic spaces that are context and emotion aware, objects nearby will be act as local producers of music to either amplify or address the emotions that humans are feeling. 
% gateway cos two way in and out 
%\textit{We create music because of the emotions we wish to express}. Sentence here. 
% music to express/share
% i am heartbroken when i hear some song i can get to understand more what im feeling
% this music blends with my emotion and it amplifies 
% i am a musician i am expressing my feelings with music 
% music comes from emotions and we create music to retain, continue experiencing these emotions
% 
\section{Design Scenarios}
To better explain how we re-imagined this natural music interface, we describe three design scenarios with our vision in different contexts. %First scenario is listen to music while doing water sports (such as surfing, scuba diving, etc) without the need for waterproof music gear. Second, we imagine humans being able to listen to music in vacuum spaces such as outer space. We also utilise \textit{the sound of planets, stars and galaxies} as objects to create music from their vibrations. Third, we present a scenario where humans can easily augment their emotional experiences using music with the blink of an eye. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{acmart-master-2/samples/surfbnw.png}
  \caption{Concept: Listening to music while surfing in the wide ocean will no longer require waterproof music gear. Rather, natural elements that are interlinked together create vibrations that humans can hear. Humans can finally achieve a non-obtrusive way of listening music while enjoying their wet hobbies. }
  \Description{Figure of a surfer headed to the sea listening to music without the need of special gear.}
  \label{fig: surf}
\end{figure}
% scenario : swimming in corals/alone in the forest. describe tech. add photos

%\textit{No need to add background music in watersport videos; you listen to them as you surf}. 
\textit{Surfing}
It is a perfect sunny day. The wind blows nice, and the water is just right. Cuauhtli decides that these are perfect conditions to go surfing (as seen in Fig \ref{fig: surf}). He prefers to feel the adrenaline rush with the sound of rock music. If we were in 2020, Cuauhtli would have to wear water-proof tightly onto his ears to prevent it from falling off. However, when surfing he has to hear the surroundings as well for his safety. %perfectly in order to surf properly and not endanger his life. 
In order to do this, he has to balance spatial awareness and enjoy at the same time, which takes a lot of effort \cite{fuchs2018dancing}. But if Cuahtli has to wear a headset, this will be problematic since he will struggle with hearing the background noise. Cuauhtli in 2121 will not have this problem anymore since, not only can he hear his preferred rock music, but he can also hear this as it blends with the sound of the environment around him. Not only that, if Cuauhtli wants to listen to the environment, the algorithm understands this and can mute the music in full - just through his thoughts. This can be done using two approaches. First, Cuauthli can listen to his favorite track in full sound and when he wants to listen to the background noise, his neurological link will understand this and allow the environment sound to be heard all the way to his brain. Second, the noise of the environment around him can be used as an input and then be processed to create a dynamic track. This will be based on Cuauthli's favorite songs. Algorithms produce a specific tune that fits his current preferences and allows him to not lose his sense as he dives deep into the sea. 

% scenario: algorithms that easily convert our emotion stimuli into actual music
\textit{Creating music from vacuum spaces using the sound of space}. Sentence here. 
%NUWAN also add your stuff here. Like the previous scenario. 

% discovering new music 
\textit{Amplifying emotions at the blink of an eye}. It is a rainy day and Cuauthli is sitting by the window, thinking about his lover. Since he is in Germany for a research visit, he misses his significant other dearly. Cuauthli would love to get lost on his thoughts about her. He then decides to listen to a song, which helps him to keep thinking about his lover. The music helps him to draw all the memories because it helps him to concentrate on her, on the memories of her by. This is done by reducing other background noise as inputs and allows him to focus on the memories that are in his brain. And after a short while, now the rain is over and Cuauthli needs to go back to work, currently feeling somewhat depressed. Now, he listens to a song which helps him to focus on his work. This changes his mood to a happy and exciting one. To do this all, all that Cuauthli needs to do is think about that one thing that he needs to do. The algorithms and his neurological link will take care of processing these thoughts and produce the sounds that he needs to hear. 

\section{Conclusion}
The visions and scenarios we presented come with their respective issues and challenges in implementation and in policy design. If we imagine a natural and seamless interface, evaluating its usability will introduce a new paradigm for HCI researchers. Will existing models such as Fitts' Law (which has always worked on any interface developed - mechanical, digital, virtual) still work in neurological links managed by our seamless thoughts? The intangible interaction provided by this \textit{"online network"} could potentially blur concepts such as piracy and intellectual property. As music is composed by ubiquitous algorithms connected to our personal thoughts and feelings, are all our emotions and the music that are generated by them considered unique? shareable? These among many others are interesting questions that we leave to our readers as we re-imagined a natural music interface. While these visions appear to be very far from reality, we are only left with our own thoughts to begin with and maybe hopefully in the not so near future too. 



%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


\end{document}
\endinput
%%
%% End of file `sample-sigchi.tex'.
